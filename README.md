# ğŸ§  AI-Powered Data Quality Profiler and Fixer

A lightweight, local-first tool for **profiling**, **explaining**, and **suggesting fixes for data quality issues** using machine learning and large language models (LLMs).

Built with:

* ğŸ“Š `pandas` and `ydata-profiling` for deep data inspection
* ğŸ¤– LLMs (via [Ollama](https://ollama.com)) for local, AI-generated insights
* âš¡ Designed to run fully offline using small models like `tinyllama`

---

## âœ… Features Implemented So Far

* ğŸ“… Upload and profile any CSV file
* ğŸ“ˆ Generate a rich interactive HTML report
* ğŸ§  Use local LLM to:

  * Explain data quality issues (missing values, type mismatches, outliers, etc.)
  * Suggest intelligent data cleaning steps
* âœï¸ Automatically embed AI-generated analysis into the profiling report

---

## ğŸ“‚ Project Structure

```
ai-data-quality-profiler/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                  # Driver script
â”‚   â”œâ”€â”€ dq_profiler.py           # Profiling & reporting logic
â”‚   â””â”€â”€ ai_explainer.py          # LLM-based insights (via Ollama)
â”œâ”€â”€ data/                        # Sample datasets (e.g., telco.csv)
â”œâ”€â”€ reports/                     # HTML reports with embedded AI analysis
â”œâ”€â”€ notebooks/                   # EDA or experiments (optional)
â”œâ”€â”€ tests/                       # Future unit tests
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ How to Run Locally

### 1. Set up the project

```bash
git clone https://github.com/your-username/ai-data-quality-profiler.git
cd ai-data-quality-profiler
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 2. Install and start Ollama

```bash
curl -fsSL https://ollama.com/install.sh | sh
ollama run tinyllama
```

> â— You need \~4GB RAM. If `mistral` doesnâ€™t fit, use `tinyllama`.

### 3. Run the profiler

```bash
python app/main.py
```

Then open the report:

```bash
xdg-open reports/profile.html
```

---

## ğŸ“Š Dataset Used

**Telco Customer Churn**
A public dataset with a mix of numerical, categorical, and messy values â€” ideal for data quality profiling.

Source: [Kaggle Dataset](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)

---

## ğŸ“Œ What's Next

* [ ] Apply selected fix suggestions automatically
* [ ] Generate cleaned dataset with comparison
* [ ] Add Streamlit UI for upload â†’ profile â†’ fix workflow
* [ ] Enable custom rule-based validations (Great Expectations or similar)
* [ ] Add test coverage and CI

---

## ï¿½ï¿½ License

MIT License Â© 2025 Sneha Shrivastav

---

## ğŸ’– Acknowledgments

* [YData Profiling](https://github.com/ydataai/ydata-profiling)
* [Ollama](https://ollama.com/) for local LLMs
* [TinyLlama](https://huggingface.co/TinyLlama) â€” small but mighty!

